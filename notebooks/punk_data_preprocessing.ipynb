{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_punk_df = pd.read_csv('../data/subset_punk_bands.csv')\n",
    "subset_punk_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Input, Embedding, Dropout, concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"randomly\" choose one band to test if model works\n",
    "yellowcard = subset_punk_df.LYRICS[subset_punk_df.ARTIST_NAME == 'yellowcard']\n",
    "\n",
    "\n",
    "# for full model\n",
    "# take out spaces in the artist names\n",
    "new_artist_names = [re.sub(r'\\W', '', string = subset_punk_df.ARTIST_NAME[w]) for w in range(len(subset_punk_df.ARTIST_NAME))]\n",
    "\n",
    "tokenizer_artist = Tokenizer()\n",
    "tokenizer_artist.fit_on_texts(new_artist_names)\n",
    "artist_seq = tokenizer_artist.texts_to_sequences(new_artist_names)\n",
    "\n",
    "tokenizer_lyrics = Tokenizer()\n",
    "tokenizer_lyrics.fit_on_texts([str(lyr) for lyr in subset_punk_df.LYRICS])\n",
    "\n",
    "token_seq = tokenizer_lyrics.texts_to_sequences([str(lyr) for lyr in subset_punk_df.LYRICS])\n",
    "\n",
    "\n",
    "n_gram_seq = []\n",
    "artists = []\n",
    "# for every line in tokenized sequences\n",
    "for line, band in zip(token_seq, artist_seq):\n",
    "    # used to append the token_seq starting from 0th element to 1st element\n",
    "    for length in range(2, len(line)):\n",
    "        n_gram_seq.append(line[:length])\n",
    "        artists.append(band)\n",
    "        \n",
    "artists = np.array(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create padded sequences\n",
    "n_gram_seq_padded = pad_sequences(n_gram_seq, maxlen = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,  700, 1615],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  700, 1615,   17],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  700, 1615,   17,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,  700, 1615,   17,    3, 1452],\n",
       "       [   0,    0,    0,    0,    0,  700, 1615,   17,    3, 1452,   90],\n",
       "       [   0,    0,    0,    0,  700, 1615,   17,    3, 1452,   90,   20],\n",
       "       [   0,    0,    0,  700, 1615,   17,    3, 1452,   90,   20,  155],\n",
       "       [   0,    0,  700, 1615,   17,    3, 1452,   90,   20,  155,    7],\n",
       "       [   0,  700, 1615,   17,    3, 1452,   90,   20,  155,    7,  425],\n",
       "       [ 700, 1615,   17,    3, 1452,   90,   20,  155,    7,  425,    2],\n",
       "       [1615,   17,    3, 1452,   90,   20,  155,    7,  425,    2,  407]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_seq_padded[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTIST_NAME</th>\n",
       "      <th>ARTIST_URL</th>\n",
       "      <th>SONG_NAME</th>\n",
       "      <th>SONG_URL</th>\n",
       "      <th>LYRICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>i can't do the one-two step</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/ica...</td>\n",
       "      <td>front page of the magazine said don't believe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>the girl's a straight-up hustler</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/the...</td>\n",
       "      <td>lipstick has a way of leaving more than just a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>sticks, stones, and techno</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/sti...</td>\n",
       "      <td>you spin your words like a record in motion st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>coffee shop soundtrack</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/cof...</td>\n",
       "      <td>should i write myself out of the history books...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>break out! break out!</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/bre...</td>\n",
       "      <td>luck loves me not tonight i'm running out this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>what appears</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/wha...</td>\n",
       "      <td>slow steady hands waving their last goodbye th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>got yours</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/got...</td>\n",
       "      <td>stacking bricks on broken ground building towe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>a place we set afire</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/apl...</td>\n",
       "      <td>you feel it you boxed it by the youth you left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>leave a light on</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/lea...</td>\n",
       "      <td>so where are you and how's it been how's the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>the hurt is gone</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/the...</td>\n",
       "      <td>watch winter melt away look for longer days th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ARTIST_NAME                                  ARTIST_URL  \\\n",
       "0    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "1    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "2    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "3    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "4    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "..            ...                                         ...   \n",
       "544    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "545    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "546    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "547    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "548    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "\n",
       "                            SONG_NAME  \\\n",
       "0         i can't do the one-two step   \n",
       "1    the girl's a straight-up hustler   \n",
       "2          sticks, stones, and techno   \n",
       "3              coffee shop soundtrack   \n",
       "4               break out! break out!   \n",
       "..                                ...   \n",
       "544                      what appears   \n",
       "545                         got yours   \n",
       "546              a place we set afire   \n",
       "547                  leave a light on   \n",
       "548                  the hurt is gone   \n",
       "\n",
       "                                              SONG_URL  \\\n",
       "0    https://www.azlyrics.com/lyrics/alltimelow/ica...   \n",
       "1    https://www.azlyrics.com/lyrics/alltimelow/the...   \n",
       "2    https://www.azlyrics.com/lyrics/alltimelow/sti...   \n",
       "3    https://www.azlyrics.com/lyrics/alltimelow/cof...   \n",
       "4    https://www.azlyrics.com/lyrics/alltimelow/bre...   \n",
       "..                                                 ...   \n",
       "544  https://www.azlyrics.com/lyrics/yellowcard/wha...   \n",
       "545  https://www.azlyrics.com/lyrics/yellowcard/got...   \n",
       "546  https://www.azlyrics.com/lyrics/yellowcard/apl...   \n",
       "547  https://www.azlyrics.com/lyrics/yellowcard/lea...   \n",
       "548  https://www.azlyrics.com/lyrics/yellowcard/the...   \n",
       "\n",
       "                                                LYRICS  \n",
       "0    front page of the magazine said don't believe ...  \n",
       "1    lipstick has a way of leaving more than just a...  \n",
       "2    you spin your words like a record in motion st...  \n",
       "3    should i write myself out of the history books...  \n",
       "4    luck loves me not tonight i'm running out this...  \n",
       "..                                                 ...  \n",
       "544  slow steady hands waving their last goodbye th...  \n",
       "545  stacking bricks on broken ground building towe...  \n",
       "546  you feel it you boxed it by the youth you left...  \n",
       "547  so where are you and how's it been how's the w...  \n",
       "548  watch winter melt away look for longer days th...  \n",
       "\n",
       "[549 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_punk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels by using One Hot Encoding \n",
    "labels = to_categorical(n_gram_seq_padded[:,-1:])\n",
    "X = n_gram_seq_padded[:,:-1]\n",
    "\n",
    "# training size (0.8 of the model)\n",
    "train_size = round(n_gram_seq_padded.shape[0]*0.8)\n",
    "# get randomly chosen indices of artists for training\n",
    "ids = np.random.choice(range(len(artists)), train_size, replace = False)\n",
    "\n",
    "# create test and train\n",
    "y_train = labels[ids]\n",
    "y_test = np.delete(labels, ids, axis = 0)\n",
    "\n",
    "lyrics_train = X[ids]\n",
    "lyrics_test = np.delete(X, ids, axis = 0)\n",
    "\n",
    "artist_train = artists[ids]\n",
    "artist_test = np.delete(artists, ids, axis = 0)\n",
    "\n",
    "# find largest vocab size in padded sequence; this is input size\n",
    "vocab_size = max([w for sentence in n_gram_seq_padded for w in sentence]) + 1\n",
    "artist_size = max([len(art) for art in artists]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two inputs\n",
    "inputA = Input(shape = (10, ))\n",
    "inputB = Input(shape = (1,))\n",
    "\n",
    "# first branch for first input\n",
    "lyrics = Embedding(input_dim = vocab_size, output_dim = 64, input_length = 10)(inputA)\n",
    "lyrics = Bidirectional(LSTM(128, return_sequences = True))(lyrics)\n",
    "lyrics = Dropout(0.2)(lyrics)\n",
    "lyrics = LSTM(64)(lyrics)\n",
    "lyrics = Dense(round(vocab_size/2), activation = 'relu')(lyrics)\n",
    "lyrics = Dense(vocab_size, activation = 'softmax')(lyrics)\n",
    "lyrics = Model(inputs = inputA, outputs = lyrics)\n",
    "\n",
    "# second branch for second input\n",
    "artist = Dense(64, activation = 'relu')(inputB)\n",
    "artist = Dense(10, activation = 'relu')(artist)\n",
    "artist = Dense(vocab_size, activation = 'relu')(artist)\n",
    "artist = Model(inputs = inputB, outputs = artist)\n",
    "\n",
    "\n",
    "# combine output of branches\n",
    "combined = concatenate([lyrics.output, artist.output])\n",
    "\n",
    "\n",
    "z = Dense(2, activation = 'relu')(combined)\n",
    "z = Dense(vocab_size, activation = 'softmax')(z)\n",
    "model = keras.Model(inputs = [lyrics.input, artist.input], outputs = z)\n",
    "\n",
    "#compile model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 64)       382656      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 10, 256)      197632      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10, 256)      0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           82176       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2990)         194350      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           650         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5979)         17883189    dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5979)         65769       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 11958)        0           dense_1[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            23918       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5979)         17937       dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,848,405\n",
      "Trainable params: 18,848,405\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3356/3356 [==============================] - 673s 198ms/step - loss: 6.5211 - accuracy: 0.0383 - val_loss: 6.2102 - val_accuracy: 0.0384\n",
      "Epoch 2/8\n",
      "3356/3356 [==============================] - 739s 220ms/step - loss: 6.1648 - accuracy: 0.0384 - val_loss: 6.2382 - val_accuracy: 0.0384\n",
      "Epoch 3/8\n",
      "3356/3356 [==============================] - 877s 261ms/step - loss: 6.1506 - accuracy: 0.0383 - val_loss: 6.2928 - val_accuracy: 0.0363\n",
      "Epoch 4/8\n",
      "3356/3356 [==============================] - 792s 236ms/step - loss: 6.1588 - accuracy: 0.0381 - val_loss: 6.3027 - val_accuracy: 0.0418\n",
      "Epoch 5/8\n",
      "3356/3356 [==============================] - 985s 293ms/step - loss: 6.1494 - accuracy: 0.0385 - val_loss: 6.3262 - val_accuracy: 0.0363\n",
      "Epoch 6/8\n",
      "3356/3356 [==============================] - 848s 253ms/step - loss: 6.1491 - accuracy: 0.0386 - val_loss: 6.3561 - val_accuracy: 0.0363\n",
      "Epoch 7/8\n",
      "3356/3356 [==============================] - 562s 167ms/step - loss: 6.1435 - accuracy: 0.0373 - val_loss: 6.3599 - val_accuracy: 0.0384\n",
      "Epoch 8/8\n",
      "3356/3356 [==============================] - 608s 181ms/step - loss: 6.1429 - accuracy: 0.0387 - val_loss: 6.3451 - val_accuracy: 0.0377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff618cb28d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit([lyrics_train, artist_train], y_train, epochs = 8, validation_data = ([lyrics_test, artist_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and tokenizers\n",
    "model.save('../punk_rock_generator.h5')\n",
    "\n",
    "with open('../lyrics_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer_lyrics, f)\n",
    "    \n",
    "with open('../artist_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer_artist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(prompt, author, length = 20):\n",
    "    '''\n",
    "    prompt: string of lyrics\n",
    "    length: length of lyrics that is wanted (includes prompt)\n",
    "    '''\n",
    "    # edge case; if prompt is as long as the length wanted\n",
    "    if len(prompt.split(' ')) == length:\n",
    "        return prompt\n",
    "    elif subset_punk_df.ARTIST_NAME.str.contains(author).any() == False:\n",
    "        return f'Artist not found! Try one of the following artists:\\n{np.unique(subset_punk_df.ARTIST_NAME)}'\n",
    "    else:\n",
    "        a = [re.sub(r'\\W', '', string = author)]\n",
    "        \n",
    "        a = np.array(tokenizer_artist.texts_to_sequences(a))\n",
    "        \n",
    "        for _ in range(20 - len(prompt.split(' '))):\n",
    "\n",
    "            token_list = tokenizer_lyrics.texts_to_sequences([prompt])[0]\n",
    "            token_padded = pad_sequences([token_list], maxlen = 10)\n",
    "\n",
    "            # get predicted probability for each word\n",
    "            predicted_probs = model.predict([token_padded, a])[0]\n",
    "\n",
    "            # using temperature for next word\n",
    "            probabilities = np.exp(predicted_probs / 1)\n",
    "            normalized_probablities = probabilities / sum(probabilities)\n",
    "            next_word = np.random.choice(range(vocab_size), p=normalized_probablities)\n",
    "            next_word = tokenizer_lyrics.index_word[next_word]\n",
    "\n",
    "\n",
    "            # add word to the prompt\n",
    "            if len(next_word) > 1 and (next_word != 'a' or next_word != 'i'):\n",
    "                prompt += ' ' + str(next_word)\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = \"there's a place off ocean avenue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's a place off ocean avenue incinerate pitchfork argyle necks smilecovered borrow loyalty holidays aftermath tomb winters confidence forget belonged\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(oa, 'all time low', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's a place off ocean avenue map problem eagles wet geeks leads 4am inscriptions grip design bumped musclesuse june salt\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(oa, 'yellowcard', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist not found! Try one of the following artists:\n",
      "['all time low' 'dashboard confessional' 'day to remember, a'\n",
      " 'good charlotte' 'green day' 'jimmy eat world' 'menzingers, the'\n",
      " 'my chemical romance' 'paramore' 'simple plan' 'state champs'\n",
      " 'story of the year' 'story so far, the' 'taking back sunday' 'yellowcard']\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(oa, '5 seconds of summer', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's a place off ocean avenue baby grease turnin' busted undercurrent cuts samsa search ages sun twice hateful engagement dud\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(oa, 'day to remember, a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's a place off ocean avenue practice value extremes listening inspired dashboard boxes cross train 2003 observe mean distaste exist\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(oa, 'my chemical romance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5ab235774e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss & accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.axhline(y=1, color='gray', linestyle='--')\n",
    "plt.title('loss & accuracy')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
