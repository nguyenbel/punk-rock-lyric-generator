{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from string import ascii_lowercase\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punk_df = pd.read_csv('data/punk_bands.csv')\n",
    "punk_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTIST_NAME</th>\n",
       "      <th>ARTIST_URL</th>\n",
       "      <th>SONG_NAME</th>\n",
       "      <th>SONG_URL</th>\n",
       "      <th>LYRICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 seconds of summer</td>\n",
       "      <td>https://www.azlyrics.com/19/5secondsofsummer.html</td>\n",
       "      <td>gotta get out</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/5secondsofsumm...</td>\n",
       "      <td>even when the sky is falling down even when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 seconds of summer</td>\n",
       "      <td>https://www.azlyrics.com/19/5secondsofsummer.html</td>\n",
       "      <td>better man</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/5secondsofsumm...</td>\n",
       "      <td>find me at a quarter to three cigarette in my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 seconds of summer</td>\n",
       "      <td>https://www.azlyrics.com/19/5secondsofsummer.html</td>\n",
       "      <td>more</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/5secondsofsumm...</td>\n",
       "      <td>if me and you are living in the same place why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 seconds of summer</td>\n",
       "      <td>https://www.azlyrics.com/19/5secondsofsummer.html</td>\n",
       "      <td>why won't you love me</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/5secondsofsumm...</td>\n",
       "      <td>switching into airplane mode again we're not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 seconds of summer</td>\n",
       "      <td>https://www.azlyrics.com/19/5secondsofsummer.html</td>\n",
       "      <td>woke up in japan</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/5secondsofsumm...</td>\n",
       "      <td>i woke up in japan feeling low feeling lonely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>zebrahead</td>\n",
       "      <td>https://www.azlyrics.com/z/zebrahead.html</td>\n",
       "      <td>out of control</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/zebrahead/outo...</td>\n",
       "      <td>i'm a mad man with a mission like a nightmare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>zebrahead</td>\n",
       "      <td>https://www.azlyrics.com/z/zebrahead.html</td>\n",
       "      <td>photographs</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/zebrahead/phot...</td>\n",
       "      <td>i am alive i am awake not like i'm not aware i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>zebrahead</td>\n",
       "      <td>https://www.azlyrics.com/z/zebrahead.html</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/zebrahead/poli...</td>\n",
       "      <td>firewall school halls cop cars protecting you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>zebrahead</td>\n",
       "      <td>https://www.azlyrics.com/z/zebrahead.html</td>\n",
       "      <td>with legs like that</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/zebrahead/with...</td>\n",
       "      <td>here she comes again like good medicine every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>zebrahead</td>\n",
       "      <td>https://www.azlyrics.com/z/zebrahead.html</td>\n",
       "      <td>wookie</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/zebrahead/wook...</td>\n",
       "      <td>in a cantina on tatoinea a kereoki wookie sing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2539 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ARTIST_NAME                                         ARTIST_URL  \\\n",
       "0     5 seconds of summer  https://www.azlyrics.com/19/5secondsofsummer.html   \n",
       "1     5 seconds of summer  https://www.azlyrics.com/19/5secondsofsummer.html   \n",
       "2     5 seconds of summer  https://www.azlyrics.com/19/5secondsofsummer.html   \n",
       "3     5 seconds of summer  https://www.azlyrics.com/19/5secondsofsummer.html   \n",
       "4     5 seconds of summer  https://www.azlyrics.com/19/5secondsofsummer.html   \n",
       "...                   ...                                                ...   \n",
       "2534            zebrahead          https://www.azlyrics.com/z/zebrahead.html   \n",
       "2535            zebrahead          https://www.azlyrics.com/z/zebrahead.html   \n",
       "2536            zebrahead          https://www.azlyrics.com/z/zebrahead.html   \n",
       "2537            zebrahead          https://www.azlyrics.com/z/zebrahead.html   \n",
       "2538            zebrahead          https://www.azlyrics.com/z/zebrahead.html   \n",
       "\n",
       "                  SONG_NAME  \\\n",
       "0             gotta get out   \n",
       "1                better man   \n",
       "2                      more   \n",
       "3     why won't you love me   \n",
       "4          woke up in japan   \n",
       "...                     ...   \n",
       "2534         out of control   \n",
       "2535            photographs   \n",
       "2536               politics   \n",
       "2537    with legs like that   \n",
       "2538                 wookie   \n",
       "\n",
       "                                               SONG_URL  \\\n",
       "0     https://www.azlyrics.com/lyrics/5secondsofsumm...   \n",
       "1     https://www.azlyrics.com/lyrics/5secondsofsumm...   \n",
       "2     https://www.azlyrics.com/lyrics/5secondsofsumm...   \n",
       "3     https://www.azlyrics.com/lyrics/5secondsofsumm...   \n",
       "4     https://www.azlyrics.com/lyrics/5secondsofsumm...   \n",
       "...                                                 ...   \n",
       "2534  https://www.azlyrics.com/lyrics/zebrahead/outo...   \n",
       "2535  https://www.azlyrics.com/lyrics/zebrahead/phot...   \n",
       "2536  https://www.azlyrics.com/lyrics/zebrahead/poli...   \n",
       "2537  https://www.azlyrics.com/lyrics/zebrahead/with...   \n",
       "2538  https://www.azlyrics.com/lyrics/zebrahead/wook...   \n",
       "\n",
       "                                                 LYRICS  \n",
       "0     even when the sky is falling down even when th...  \n",
       "1     find me at a quarter to three cigarette in my ...  \n",
       "2     if me and you are living in the same place why...  \n",
       "3      switching into airplane mode again we're not ...  \n",
       "4     i woke up in japan feeling low feeling lonely ...  \n",
       "...                                                 ...  \n",
       "2534  i'm a mad man with a mission like a nightmare ...  \n",
       "2535  i am alive i am awake not like i'm not aware i...  \n",
       "2536  firewall school halls cop cars protecting you ...  \n",
       "2537  here she comes again like good medicine every ...  \n",
       "2538  in a cantina on tatoinea a kereoki wookie sing...  \n",
       "\n",
       "[2539 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Input, Embedding, Dropout, concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"randomly\" choose one band to test if model works\n",
    "yellowcard = punk_df.LYRICS[punk_df.ARTIST_NAME == 'yellowcard']\n",
    "\n",
    "\n",
    "# for full model\n",
    "# take out spaces in the artist names\n",
    "new_artist_names = [re.sub(r'\\W', '', string = punk_df.ARTIST_NAME[w]) for w in range(len(punk_df.ARTIST_NAME))]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts([str(lyr) for lyr in punk_df.LYRICS])\n",
    "\n",
    "token_seq = tokenizer.texts_to_sequences([str(lyr) for lyr in punk_df.LYRICS])\n",
    "tokenizer.fit_on_texts(new_artist_names)\n",
    "artist_seq = tokenizer.texts_to_sequences(new_artist_names)\n",
    "\n",
    "n_gram_seq = []\n",
    "artists = []\n",
    "# for every line in tokenized sequences\n",
    "for line, band in zip(token_seq, artist_seq):\n",
    "    # used to append the token_seq starting from 0th element to 1st element\n",
    "    for length in range(2, len(line)):\n",
    "        n_gram_seq.append(line[:length])\n",
    "        artists.append(band)\n",
    "        \n",
    "artists = np.array(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create padded sequences\n",
    "n_gram_seq_padded = pad_sequences(n_gram_seq, maxlen = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0, 189,  33],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 189,  33,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 189,  33,   3, 366],\n",
       "       [  0,   0,   0,   0,   0,   0, 189,  33,   3, 366,  22],\n",
       "       [  0,   0,   0,   0,   0, 189,  33,   3, 366,  22, 247],\n",
       "       [  0,   0,   0,   0, 189,  33,   3, 366,  22, 247,  45],\n",
       "       [  0,   0,   0, 189,  33,   3, 366,  22, 247,  45, 189],\n",
       "       [  0,   0, 189,  33,   3, 366,  22, 247,  45, 189,  33],\n",
       "       [  0, 189,  33,   3, 366,  22, 247,  45, 189,  33,   3],\n",
       "       [189,  33,   3, 366,  22, 247,  45, 189,  33,   3, 893],\n",
       "       [ 33,   3, 366,  22, 247,  45, 189,  33,   3, 893,  22]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_seq_padded[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels by using One Hot Encoding \n",
    "labels = to_categorical(n_gram_seq_padded[:,-1:])\n",
    "X = n_gram_seq_padded[:,:-1]\n",
    "bands = artists[:,:-1]\n",
    "\n",
    "train_size = round(n_gram_seq_padded.shape[0]*0.8)\n",
    "\n",
    "# create test and train\n",
    "y_train = labels[:train_size:]\n",
    "y_test = labels[train_size:,:]\n",
    "\n",
    "lyrics_train = X[:train_size, :]\n",
    "lyrics_test = X[train_size:,:]\n",
    "\n",
    "artist_train = bands[:train_size, :]\n",
    "artist_test = bands[train_size:,:]\n",
    "\n",
    "# find largest vocab size in padded sequence; this is input size\n",
    "vocab_size = max([w for sentence in n_gram_seq_padded for w in sentence]) + 1\n",
    "artist_size = max([len(art) for art in artists]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two inputs\n",
    "inputA = Input(shape = (10, ))\n",
    "inputB = Input(shape = (0,))\n",
    "\n",
    "# first branch for first input\n",
    "lyrics = Embedding(input_dim = vocab_size, output_dim = 64, input_length = 10)(inputA)\n",
    "lyrics = Bidirectional(LSTM(128, return_sequences = True))(lyrics)\n",
    "lyrics = Dropout(0.2)(lyrics)\n",
    "lyrics = LSTM(64)(lyrics)\n",
    "lyrics = Dense(round(vocab_size/2), activation = 'relu')(lyrics)\n",
    "lyrics = Dense(vocab_size, activation = 'softmax')(lyrics)\n",
    "lyrics = Model(inputs = inputA, outputs = lyrics)\n",
    "\n",
    "# second branch for second input\n",
    "artist = Dense(64, activation = 'relu')(inputB)\n",
    "artist = Dense(10, activation = 'relu')(artist)\n",
    "artist = Dense(vocab_size, activation = 'relu')(artist)\n",
    "artist = Model(inputs = inputB, outputs = artist)\n",
    "\n",
    "\n",
    "# combine output of branches\n",
    "combined = concatenate([lyrics.output, artist.output])\n",
    "\n",
    "\n",
    "z = Dense(2, activation = 'relu')(combined)\n",
    "z = Dense(vocab_size, activation = 'softmax')(z)\n",
    "model = keras.Model(inputs = [lyrics.input, artist.input], outputs = z)\n",
    "\n",
    "#compile model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 64)       914432      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 10, 256)      197632      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10, 256)      0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 0)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           82176       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           64          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7144)         464360      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           650         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 14288)        102087760   dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 14288)        157168      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28576)        0           dense_1[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            57154       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 14288)        42864       dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 104,004,260\n",
      "Trainable params: 104,004,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15020/15020 [==============================] - 9443s 628ms/step - loss: 6.8936 - accuracy: 0.0368 - val_loss: 6.4249 - val_accuracy: 0.0353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbda647a50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([lyrics_train, artist_train], y_train, epochs = 1, validation_data = ([lyrics_test, artist_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(prompt, author, length):\n",
    "    '''\n",
    "    prompt: string of lyrics\n",
    "    length: length of lyrics that is wanted (includes prompt)\n",
    "    '''\n",
    "    # edge case; if prompt is as long as the length wanted\n",
    "    if len(prompt.split(' ')) == length:\n",
    "        return prompt\n",
    "    else:\n",
    "        for _ in range(length - len(prompt.split(' '))):\n",
    "            \n",
    "            token_list = tokenizer.texts_to_sequences([prompt])[0]\n",
    "            token_padded = pad_sequences([token_list], maxlen = 11)\n",
    "            \n",
    "            # get predicted probability for each word\n",
    "            predicted_probs = model.predict(token_padded)[0]\n",
    "            \n",
    "            # find max probability of the each word\n",
    "            word_choice = predicted_probs.argmax()\n",
    "            \n",
    "            # find out what the word is\n",
    "            output_word = tokenizer.index_word[word_choice]\n",
    "            \n",
    "            # add word to the prompt\n",
    "            prompt += ' ' + output_word\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_lyrics(\"eyes are feeling heavy but they never seem to close\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_lyrics(\"there's a place off ocean avenue\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts([str(lyr) for lyr in punk_df.LYRICS])\n",
    "\n",
    "token_seq = tokenizer.texts_to_sequences([str(lyr) for lyr in punk_df.LYRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
