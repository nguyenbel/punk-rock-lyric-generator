{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from string import ascii_lowercase\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_punk_df = pd.read_csv('../data/subset_punk_bands.csv')\n",
    "subset_punk_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Input, Embedding, Dropout, concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"randomly\" choose one band to test if model works\n",
    "yellowcard = subset_punk_df.LYRICS[subset_punk_df.ARTIST_NAME == 'yellowcard']\n",
    "\n",
    "\n",
    "# for full model\n",
    "# take out spaces in the artist names\n",
    "new_artist_names = [re.sub(r'\\W', '', string = subset_punk_df.ARTIST_NAME[w]) for w in range(len(subset_punk_df.ARTIST_NAME))]\n",
    "\n",
    "tokenizer_artist = Tokenizer()\n",
    "tokenizer_artist.fit_on_texts(new_artist_names)\n",
    "artist_seq = tokenizer_artist.texts_to_sequences(new_artist_names)\n",
    "\n",
    "tokenizer_lyrics = Tokenizer()\n",
    "tokenizer_lyrics.fit_on_texts([str(lyr) for lyr in subset_punk_df.LYRICS])\n",
    "\n",
    "token_seq = tokenizer_lyrics.texts_to_sequences([str(lyr) for lyr in subset_punk_df.LYRICS])\n",
    "\n",
    "\n",
    "n_gram_seq = []\n",
    "artists = []\n",
    "# for every line in tokenized sequences\n",
    "for line, band in zip(token_seq, artist_seq):\n",
    "    # used to append the token_seq starting from 0th element to 1st element\n",
    "    for length in range(2, len(line)):\n",
    "        n_gram_seq.append(line[:length])\n",
    "        artists.append(band)\n",
    "        \n",
    "artists = np.array(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create padded sequences\n",
    "n_gram_seq_padded = pad_sequences(n_gram_seq, maxlen = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,  700, 1615],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  700, 1615,   17],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  700, 1615,   17,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,  700, 1615,   17,    3, 1452],\n",
       "       [   0,    0,    0,    0,    0,  700, 1615,   17,    3, 1452,   90],\n",
       "       [   0,    0,    0,    0,  700, 1615,   17,    3, 1452,   90,   20],\n",
       "       [   0,    0,    0,  700, 1615,   17,    3, 1452,   90,   20,  155],\n",
       "       [   0,    0,  700, 1615,   17,    3, 1452,   90,   20,  155,    7],\n",
       "       [   0,  700, 1615,   17,    3, 1452,   90,   20,  155,    7,  425],\n",
       "       [ 700, 1615,   17,    3, 1452,   90,   20,  155,    7,  425,    2],\n",
       "       [1615,   17,    3, 1452,   90,   20,  155,    7,  425,    2,  407]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_seq_padded[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTIST_NAME</th>\n",
       "      <th>ARTIST_URL</th>\n",
       "      <th>SONG_NAME</th>\n",
       "      <th>SONG_URL</th>\n",
       "      <th>LYRICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>i can't do the one-two step</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/ica...</td>\n",
       "      <td>front page of the magazine said don't believe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>the girl's a straight-up hustler</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/the...</td>\n",
       "      <td>lipstick has a way of leaving more than just a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>sticks, stones, and techno</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/sti...</td>\n",
       "      <td>you spin your words like a record in motion st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>coffee shop soundtrack</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/cof...</td>\n",
       "      <td>should i write myself out of the history books...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all time low</td>\n",
       "      <td>https://www.azlyrics.com/a/alltimelow.html</td>\n",
       "      <td>break out! break out!</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/alltimelow/bre...</td>\n",
       "      <td>luck loves me not tonight i'm running out this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>what appears</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/wha...</td>\n",
       "      <td>slow steady hands waving their last goodbye th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>got yours</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/got...</td>\n",
       "      <td>stacking bricks on broken ground building towe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>a place we set afire</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/apl...</td>\n",
       "      <td>you feel it you boxed it by the youth you left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>leave a light on</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/lea...</td>\n",
       "      <td>so where are you and how's it been how's the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>yellowcard</td>\n",
       "      <td>https://www.azlyrics.com/y/yellowcard.html</td>\n",
       "      <td>the hurt is gone</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/yellowcard/the...</td>\n",
       "      <td>watch winter melt away look for longer days th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ARTIST_NAME                                  ARTIST_URL  \\\n",
       "0    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "1    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "2    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "3    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "4    all time low  https://www.azlyrics.com/a/alltimelow.html   \n",
       "..            ...                                         ...   \n",
       "544    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "545    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "546    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "547    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "548    yellowcard  https://www.azlyrics.com/y/yellowcard.html   \n",
       "\n",
       "                            SONG_NAME  \\\n",
       "0         i can't do the one-two step   \n",
       "1    the girl's a straight-up hustler   \n",
       "2          sticks, stones, and techno   \n",
       "3              coffee shop soundtrack   \n",
       "4               break out! break out!   \n",
       "..                                ...   \n",
       "544                      what appears   \n",
       "545                         got yours   \n",
       "546              a place we set afire   \n",
       "547                  leave a light on   \n",
       "548                  the hurt is gone   \n",
       "\n",
       "                                              SONG_URL  \\\n",
       "0    https://www.azlyrics.com/lyrics/alltimelow/ica...   \n",
       "1    https://www.azlyrics.com/lyrics/alltimelow/the...   \n",
       "2    https://www.azlyrics.com/lyrics/alltimelow/sti...   \n",
       "3    https://www.azlyrics.com/lyrics/alltimelow/cof...   \n",
       "4    https://www.azlyrics.com/lyrics/alltimelow/bre...   \n",
       "..                                                 ...   \n",
       "544  https://www.azlyrics.com/lyrics/yellowcard/wha...   \n",
       "545  https://www.azlyrics.com/lyrics/yellowcard/got...   \n",
       "546  https://www.azlyrics.com/lyrics/yellowcard/apl...   \n",
       "547  https://www.azlyrics.com/lyrics/yellowcard/lea...   \n",
       "548  https://www.azlyrics.com/lyrics/yellowcard/the...   \n",
       "\n",
       "                                                LYRICS  \n",
       "0    front page of the magazine said don't believe ...  \n",
       "1    lipstick has a way of leaving more than just a...  \n",
       "2    you spin your words like a record in motion st...  \n",
       "3    should i write myself out of the history books...  \n",
       "4    luck loves me not tonight i'm running out this...  \n",
       "..                                                 ...  \n",
       "544  slow steady hands waving their last goodbye th...  \n",
       "545  stacking bricks on broken ground building towe...  \n",
       "546  you feel it you boxed it by the youth you left...  \n",
       "547  so where are you and how's it been how's the w...  \n",
       "548  watch winter melt away look for longer days th...  \n",
       "\n",
       "[549 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_punk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels by using One Hot Encoding \n",
    "labels = to_categorical(n_gram_seq_padded[:,-1:])\n",
    "X = n_gram_seq_padded[:,:-1]\n",
    "\n",
    "# training size (0.8 of the model)\n",
    "train_size = round(n_gram_seq_padded.shape[0]*0.8)\n",
    "# get randomly chosen indices of artists for training\n",
    "ids = np.random.choice(range(len(artists)), train_size, replace = False)\n",
    "\n",
    "# create test and train\n",
    "y_train = labels[ids]\n",
    "y_test = np.delete(labels, ids, axis = 0)\n",
    "\n",
    "lyrics_train = X[ids]\n",
    "lyrics_test = np.delete(X, ids, axis = 0)\n",
    "\n",
    "artist_train = artists[ids]\n",
    "artist_test = np.delete(artists, ids, axis = 0)\n",
    "\n",
    "# find largest vocab size in padded sequence; this is input size\n",
    "vocab_size = max([w for sentence in n_gram_seq_padded for w in sentence]) + 1\n",
    "artist_size = max([len(art) for art in artists]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two inputs\n",
    "inputA = Input(shape = (10, ))\n",
    "inputB = Input(shape = (1,))\n",
    "\n",
    "# first branch for first input\n",
    "lyrics = Embedding(input_dim = vocab_size, output_dim = 64, input_length = 10)(inputA)\n",
    "lyrics = Bidirectional(LSTM(128, return_sequences = True))(lyrics)\n",
    "lyrics = Dropout(0.2)(lyrics)\n",
    "lyrics = LSTM(64)(lyrics)\n",
    "lyrics = Dense(round(vocab_size/2), activation = 'relu')(lyrics)\n",
    "lyrics = Dense(vocab_size, activation = 'softmax')(lyrics)\n",
    "lyrics = Model(inputs = inputA, outputs = lyrics)\n",
    "\n",
    "# second branch for second input\n",
    "artist = Dense(64, activation = 'relu')(inputB)\n",
    "artist = Dense(10, activation = 'relu')(artist)\n",
    "artist = Dense(vocab_size, activation = 'relu')(artist)\n",
    "artist = Model(inputs = inputB, outputs = artist)\n",
    "\n",
    "\n",
    "# combine output of branches\n",
    "combined = concatenate([lyrics.output, artist.output])\n",
    "\n",
    "\n",
    "z = Dense(2, activation = 'relu')(combined)\n",
    "z = Dense(vocab_size, activation = 'softmax')(z)\n",
    "model = keras.Model(inputs = [lyrics.input, artist.input], outputs = z)\n",
    "\n",
    "#compile model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 64)       382656      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 10, 256)      197632      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10, 256)      0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           82176       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2990)         194350      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           650         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5979)         17883189    dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5979)         65769       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 11958)        0           dense_1[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            23918       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5979)         17937       dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,848,405\n",
      "Trainable params: 18,848,405\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3356/3356 [==============================] - 688s 203ms/step - loss: 6.5229 - accuracy: 0.0364 - val_loss: 6.2155 - val_accuracy: 0.0364\n",
      "Epoch 2/8\n",
      "3356/3356 [==============================] - 524s 156ms/step - loss: 6.1549 - accuracy: 0.0368 - val_loss: 6.2389 - val_accuracy: 0.0364\n",
      "Epoch 3/8\n",
      "3356/3356 [==============================] - 686s 205ms/step - loss: 6.1388 - accuracy: 0.0375 - val_loss: 6.2643 - val_accuracy: 0.0364\n",
      "Epoch 4/8\n",
      "3356/3356 [==============================] - 782s 233ms/step - loss: 6.1314 - accuracy: 0.0373 - val_loss: 6.2947 - val_accuracy: 0.0387\n",
      "Epoch 5/8\n",
      "3356/3356 [==============================] - 577s 172ms/step - loss: 6.1390 - accuracy: 0.0383 - val_loss: 6.3358 - val_accuracy: 0.0364\n",
      "Epoch 6/8\n",
      "3356/3356 [==============================] - 576s 172ms/step - loss: 6.1345 - accuracy: 0.0374 - val_loss: 6.3357 - val_accuracy: 0.0387\n",
      "Epoch 7/8\n",
      "3356/3356 [==============================] - 657s 196ms/step - loss: 6.1236 - accuracy: 0.0376 - val_loss: 6.3407 - val_accuracy: 0.0387\n",
      "Epoch 8/8\n",
      "3356/3356 [==============================] - 761s 227ms/step - loss: 6.1192 - accuracy: 0.0399 - val_loss: 6.3458 - val_accuracy: 0.0366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f911dc84ed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([lyrics_train, artist_train], y_train, epochs = 8, validation_data = ([lyrics_test, artist_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(prompt, author, length = 20):\n",
    "    '''\n",
    "    prompt: string of lyrics\n",
    "    length: length of lyrics that is wanted (includes prompt)\n",
    "    '''\n",
    "    # edge case; if prompt is as long as the length wanted\n",
    "    if len(prompt.split(' ')) == length:\n",
    "        return prompt\n",
    "    elif subset_punk_df.ARTIST_NAME.str.contains(author).any() == False:\n",
    "        return print(f'Artist not found! Try one of the following artists.\\n{np.unique(subset_punk_df.ARTIST_NAME)}')\n",
    "    else:\n",
    "        a = [re.sub(r'\\W', '', string = author)]\n",
    "        \n",
    "        a = np.array(tokenizer_artist.texts_to_sequences(a))\n",
    "        \n",
    "        for _ in range(20 - len(prompt.split(' '))):\n",
    "\n",
    "            token_list = tokenizer_lyrics.texts_to_sequences([prompt])[0]\n",
    "            token_padded = pad_sequences([token_list], maxlen = 10)\n",
    "\n",
    "            # get predicted probability for each word\n",
    "            predicted_probs = model.predict([token_padded, a])[0]\n",
    "\n",
    "            # using temperature for next word\n",
    "            probabilities = np.exp(predicted_probs / 1)\n",
    "            normalized_probablities = probabilities / sum(probabilities)\n",
    "            next_word = np.random.choice(range(vocab_size), p=normalized_probablities)\n",
    "            next_word = tokenizer_lyrics.index_word[next_word]\n",
    "\n",
    "\n",
    "            # add word to the prompt\n",
    "            if len(next_word) > 1 and (next_word != 'a' or next_word != 'i'):\n",
    "                prompt += ' ' + str(next_word)\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = \"there's a place off ocean avenue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's a place off ocean avenue mouldin' pace ups mais lifetime fads complication endeavor stitches fan overrated strangle wrong pairs\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(\"there's a place off ocean avenue\", 'all time low', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's a place off ocean avenue unrestful bright snotty unkind sources given ambulances laundry ahold discard lays bags resolve rewind\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(\"there's a place off ocean avenue\", 'yellowcard', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist not found! Try one of the following artists.\n",
      "['all time low' 'dashboard confessional' 'day to remember, a'\n",
      " 'good charlotte' 'green day' 'jimmy eat world' 'menzingers, the'\n",
      " 'my chemical romance' 'paramore' 'simple plan' 'state champs'\n",
      " 'story of the year' 'story so far, the' 'taking back sunday' 'yellowcard']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(generate_lyrics(\"there's a place off ocean avenue\", '5 seconds of summer', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my girlfriend likes my best friend swimming whippin' hold vapors booze clause rock'n'rollers solved juliet degenerating used adjust swell cliche's\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lyrics('my girlfriend likes my best friend', 'day to remember, a', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"there's a place off ocean avenue brightest killjoys waitress shy brown used bills fall motor girl's underdog highways collecting alcohol\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lyrics(oa, 'day to remember, a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"there's a place off ocean avenue negative razor inroads disposable satellite others questioned apology dorms teenage planned pour teaching stones\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lyrics(oa, 'my chemical romance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
